{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 1.0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "print(f'pytorch version: {torch.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L1\n",
      "----------------------------------------\n",
      "[0.705 0.906 1.308 1.509]\n",
      "\n",
      "L2\n",
      "----------------------------------------\n",
      "[ 3.03765944e-04 -1.43841367e-01  1.72753696e-01  4.53380714e-01]\n",
      "\n",
      "loss\n",
      "----------------------------------------\n",
      "2.3767862745225306\n"
     ]
    }
   ],
   "source": [
    "def np_sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def l2_loss(x, y):\n",
    "    return 0.5 * (x - y) ** 2\n",
    "\n",
    "\n",
    "x = np.array([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]])\n",
    "w1 = np.array([[0.1, -0.1], [0.2, 0.001]])\n",
    "w2 = np.array([0.0005, -0.2, 0.2, 0.5])\n",
    "y = np.array([-1., -1., 1., 1.])\n",
    "\n",
    "L_0_0 = x[0, 0] * w1[0, 0] + x[0, 1] * w1[0, 1] + x[1, 0] * w1[1, 0] + x[1, 1] * w1[1, 1]\n",
    "L_0_1 = x[0, 1] * w1[0, 0] + x[0, 2] * w1[0, 1] + x[1, 1] * w1[1, 0] + x[1, 2] * w1[1, 1]\n",
    "L_1_0 = x[1, 0] * w1[0, 0] + x[1, 1] * w1[0, 1] + x[2, 0] * w1[1, 0] + x[2, 1] * w1[1, 1]\n",
    "L_1_1 = x[1, 1] * w1[0, 0] + x[1, 2] * w1[0, 1] + x[2, 1] * w1[1, 0] + x[2, 2] * w1[1, 1]\n",
    "L1 = np.array([L_0_0, L_0_1, L_1_0, L_1_1])\n",
    "\n",
    "print('\\nL1' + '\\n' + '-' * 40)\n",
    "print(L1)\n",
    "\n",
    "L1A = np.tanh(L1)\n",
    "L2 = np.array([L1A[0] * w2[0], L1A[1] * w2[1], L1A[2] * w2[2], L1A[3] * w2[3]])\n",
    "\n",
    "print('\\nL2' + '\\n' + '-' * 40)\n",
    "print(L2)\n",
    "\n",
    "L2A = np_sigmoid(L2)\n",
    "loss = l2_loss(L2A, y).sum()\n",
    "\n",
    "print('\\nloss' + '\\n' + '-' * 40)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "d_w2\n",
      "----------------------------------------\n",
      "[ 0.22783599  0.26189097 -0.09793547 -0.08370645]\n",
      "\n",
      "d_L1\n",
      "----------------------------------------\n",
      "[ 0.0001183  -0.03515696 -0.00575761 -0.00820593]\n",
      "\n",
      "d_w1[0, 0]\n",
      "----------------------------------------\n",
      "-0.1342557202950444\n"
     ]
    }
   ],
   "source": [
    "d_w2 = (L2A - y) * np_sigmoid(L2) * (1 - np_sigmoid(L2)) * L1A.reshape(-1)\n",
    "\n",
    "print('\\nd_w2' + '\\n' + '-' * 40)\n",
    "print(d_w2)\n",
    "\n",
    "d_L1 = (L2A - y) * np_sigmoid(L2) * (1 - np_sigmoid(L2)) * w2 * (1 - np.tanh(L1) ** 2)\n",
    "\n",
    "print('\\nd_L1' + '\\n' + '-' * 40)\n",
    "print(d_L1)\n",
    "\n",
    "d_w_0_0_0 = d_L1[0] * x[0, 0]\n",
    "d_w_0_0_1 = d_L1[1] * x[0, 1]\n",
    "d_w_0_0_2 = d_L1[2] * x[1, 0]\n",
    "d_w_0_0_3 = d_L1[3] * x[1, 1]\n",
    "d_w_0_0 = d_w_0_0_0 + d_w_0_0_1 + d_w_0_0_2 + d_w_0_0_3\n",
    "\n",
    "print('\\nd_w1[0, 0]' + '\\n' + '-' * 40)\n",
    "print(d_w_0_0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch (for validation purpose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L1\n",
      "----------------------------------------\n",
      "tensor([0.7050, 0.9060, 1.3080, 1.5090], grad_fn=<CopySlices>)\n",
      "\n",
      "L2\n",
      "----------------------------------------\n",
      "tensor([ 3.0377e-04, -1.4384e-01,  1.7275e-01,  4.5338e-01],\n",
      "       grad_fn=<MulBackward0>)\n",
      "\n",
      "loss\n",
      "----------------------------------------\n",
      "tensor(2.3768, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]], requires_grad=True)\n",
    "w1 = torch.tensor([[0.1, -0.1], [0.2, 0.001]], requires_grad=True)\n",
    "w2 = torch.tensor([0.0005, -0.2, 0.2, 0.5], requires_grad=True)\n",
    "y = torch.tensor([-1., -1., 1., 1.], requires_grad=False)\n",
    "\n",
    "L1 = torch.empty(4)\n",
    "L1[0] = (x[:2, :2] * w1).sum()\n",
    "L1[1] = (x[:2, 1:] * w1).sum()\n",
    "L1[2] = (x[1:, :2] * w1).sum()\n",
    "L1[3] = (x[1:, 1:] * w1).sum()\n",
    "L1.retain_grad()\n",
    "\n",
    "# L_0_0 = (x[:2, :2] * w1).sum()\n",
    "# L_0_1 = (x[:2, 1:] * w1).sum()\n",
    "# L_1_0 = (x[1:, :2] * w1).sum()\n",
    "# L_1_1 = (x[1:, 1:] * w1).sum()\n",
    "\n",
    "# L1 = torch.cat([L_0_0.unsqueeze(0), L_0_1.unsqueeze(0), L_1_0.unsqueeze(0), L_1_1.unsqueeze(0)]).view(2, 2)\n",
    "\n",
    "print('\\nL1' + '\\n' + '-' * 40)\n",
    "print(L1)\n",
    "\n",
    "L1A = torch.tanh(L1)\n",
    "L1A.retain_grad()\n",
    "\n",
    "L2 = L1A * w2\n",
    "L2.retain_grad()\n",
    "\n",
    "print('\\nL2' + '\\n' + '-' * 40)\n",
    "print(L2)\n",
    "\n",
    "L2A = torch.sigmoid(L2)\n",
    "loss = l2_loss(L2A, y).sum()\n",
    "\n",
    "print('\\nloss' + '\\n' + '-' * 40)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "d_w2\n",
      "----------------------------------------\n",
      "tensor([ 0.2278,  0.2619, -0.0979, -0.0837])\n",
      "\n",
      "d_L1\n",
      "----------------------------------------\n",
      "tensor([ 0.0001, -0.0352, -0.0058, -0.0082])\n",
      "\n",
      "d_w1[0, 0]\n",
      "----------------------------------------\n",
      "tensor(-0.1343)\n"
     ]
    }
   ],
   "source": [
    "print('\\nd_w2' + '\\n' + '-' * 40)\n",
    "print(w2.grad)\n",
    "\n",
    "print('\\nd_L1' + '\\n' + '-' * 40)\n",
    "print(L1.grad)\n",
    "\n",
    "print('\\nd_w1[0, 0]' + '\\n' + '-' * 40)\n",
    "print(w1.grad[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
